{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from src.models.condrefinenet import CondRefineNetDilated\n",
    "from src.config import get_cfg_defaults\n",
    "from src.data import numpy2tensor, image2tensor, tensor2image, tensor2complex, tensor_split\n",
    "from src.metrics import psnr, ssim, batch_PSNR\n",
    "from src.utils_TRPA import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat,savemat\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_num = 10\n",
    "chp_path = './checkpoints/SIAT/net.pth'\n",
    "states = torch.load(chp_path)\n",
    "scorenet = CondRefineNetDilated(6,6,128).cuda()\n",
    "scorenet.load_state_dict(states['weights'])\n",
    "scorenet.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class US_pattern:\n",
    "    \n",
    "    #====================================================================\n",
    "    def generate_US_pattern_1D(self, size_2D, R, no_of_training_profs = 15):\n",
    "        #assuming a normal distribution\n",
    "        #size_2D is taken in 2D, first dimesnion is the readout direction, no undersampling there\n",
    "        #second dimension gets the undersampling pattern\n",
    "        #returns a full 2D pattern\n",
    "        #fills the [-no_of_training_profs/2, +no_of_training_profs/2] k-space center regardless of the random sampling, to mkae sure you have the k-space center\n",
    "    \n",
    "        if R==1:\n",
    "            samp_patt = np.tile(  np.ones((size_2D[1],1)).T ,(size_2D[0],1) )\n",
    "            return samp_patt \n",
    "\n",
    "        mid = np.round(size_2D[1]/2).astype(int)\n",
    "\n",
    "\n",
    "        no_of_samples=np.round(size_2D[1]/R).astype(int)\n",
    "        smps=np.zeros(no_of_samples)\n",
    "\n",
    "        for i in range(0,no_of_training_profs):\n",
    "            smps[i]=- np.floor(no_of_training_profs/2) + i\n",
    "\n",
    "        ctr= no_of_training_profs # you already have some samples in the k-space center, count them as well\n",
    "\n",
    "        while(ctr < no_of_samples ):\n",
    "            smp=np.round(np.random.randn(1)*size_2D[1]/6)\n",
    "            if np.abs(smp)< size_2D[1]/2 -1:\n",
    "                if not (smp in smps):\n",
    "                    smps[ctr]=smp\n",
    "                    ctr=ctr+1\n",
    "        #put the positions into a 1D array\n",
    "        tmp=np.zeros((size_2D[1],1))\n",
    "        inxs = mid + smps.astype(int) \n",
    "        tmp[inxs.astype(int)]=1\n",
    "        #replicate the array to get a 2D pattern image\n",
    "        samp_patt = np.tile(tmp.T,(size_2D[0],1))\n",
    "\n",
    "        return samp_patt\n",
    "    \n",
    "    #====================================================================\n",
    "    def generate_opt_US_pattern_1D(self, size_2D, R, max_iter, no_of_training_profs = 15):\n",
    "        \n",
    "        \n",
    "        if R==1:\n",
    "            opt_pt = self.generate_US_pattern_1D(size_2D,R, no_of_training_profs)\n",
    "            return opt_pt\n",
    "\n",
    "        \n",
    "        mid = np.round(size_2D[1]/2).astype(int)\n",
    "        \n",
    "\n",
    "        opt_p2s=1e10\n",
    "        opt_pt=[]\n",
    "        opt_ptf=[]\n",
    "\n",
    "        for it in range(0,max_iter):\n",
    "            pt = self.generate_US_pattern_1D(size_2D,R, no_of_training_profs)\n",
    "            ptf = np.abs( np.fft.fftshift( np.fft.fft(pt[0,:]) ) ) #just get one readout line\n",
    "            peak = np.sum(ptf[mid-1:mid+1])\n",
    "            side= np.sum(ptf[0:mid-2]) + np.sum(ptf[mid+2:])\n",
    "            peak2side = peak/side\n",
    "\n",
    "            if peak2side < opt_p2s:\n",
    "                opt_p2s = peak2side\n",
    "                opt_pt = pt\n",
    "                opt_ptf=ptf\n",
    "\n",
    "        return opt_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FT (x, sensmaps):   \n",
    "    #inp: [nx, ny]\n",
    "    #out: [nx, ny, ns]\n",
    "    return np.fft.fftshift(np.fft.fft2(sensmaps*np.tile(x[:,:,np.newaxis],[1,1,sensmaps.shape[2]]),axes=(0,1)),axes=(0,1))\n",
    "\n",
    "def tFT (x, sensmaps):\n",
    "    #inp: [nx, ny, ns]\n",
    "    #out: [nx, ny]\n",
    "    temp = np.fft.ifft2(np.fft.ifftshift( x , axes=(0,1) ),  axes=(0,1)  )\n",
    "    return np.sum( temp*np.conjugate(sensmaps) , axis=2)  / np.sum(sensmaps*np.conjugate(sensmaps),axis=2)\n",
    "\n",
    "\n",
    "def UFT(x, uspat, sensmaps):\n",
    "    #inp: [nx, ny], [nx, ny]\n",
    "    #out: [nx, ny, ns] \n",
    "    return np.tile(uspat[:,:,np.newaxis],[1,1,sensmaps.shape[2]])*FT(x, sensmaps)\n",
    "\n",
    "def tUFT(x, uspat, sensmaps):\n",
    "    #inp: [nx, ny], [nx, ny]\n",
    "    #out: [nx, ny]\n",
    "    tmp1 = np.tile(uspat[:,:,np.newaxis],[1,1,sensmaps.shape[2]])\n",
    "    return tFT(tmp1*x, sensmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('./data/ddp/acq_im_real.h5', 'r')\n",
    "kspr = np.array((f['DS1']))\n",
    "f = h5py.File('./data/ddp/acq_im_imag.h5', 'r')\n",
    "kspi = np.array((f['DS1']))\n",
    "ksp = np.rot90(np.transpose(kspr+1j*kspi),3)\n",
    "ksp = np.fft.ifftn(np.fft.fftshift(np.fft.fftn(ksp,axes=[0,1]),axes=[0,1]),axes=[0,1])\n",
    "ksp.shape\n",
    "\n",
    "f = h5py.File('./data/ddp/acq_coilmaps_espirit_real.h5', 'r')\n",
    "espsr = np.array((f['DS1']))\n",
    "f = h5py.File('./data/ddp/acq_coilmaps_espirit_imag.h5', 'r')\n",
    "espsi = np.array((f['DS1']))\n",
    "\n",
    "esps= np.rot90(np.transpose(espsr+1j*espsi),3)\n",
    "sensmaps = esps.copy()\n",
    "\n",
    "#rotate images for canonical orientation\n",
    "sensmaps=np.rot90(np.rot90(sensmaps))\n",
    "ksp=np.rot90(np.rot90(ksp))\n",
    "\n",
    "orim = tFT(ksp,sensmaps) # the fully sampled image \n",
    "\n",
    "ori_max = np.max(np.abs(orim))\n",
    "# to make the mr image divisible by four\n",
    "orim = orim[1:,:]\n",
    "sensmaps = sensmaps[1:,:]\n",
    "#normalize the espirit coil maps\n",
    "sensmaps=sensmaps/np.tile(np.sum(sensmaps*np.conjugate(sensmaps),axis=2)[:,:,np.newaxis],[1, 1, sensmaps.shape[2]])\n",
    "\n",
    "ksp = FT(orim,sensmaps)\n",
    "\n",
    "#load the undersampling pattern\n",
    "patt = np.load('./data/mask_R4.npy')[1:,:]\n",
    "patt = np.mean(patt, axis=0, keepdims=True)\n",
    "usksp = ksp * np.tile(patt[:,:,np.newaxis],[1, 1, ksp.shape[2]])\n",
    "\n",
    "# normalize the kspace\n",
    "tmp = tFT(usksp,sensmaps)\n",
    "usksp=usksp/np.max(np.abs(orim))\n",
    "mask = patt\n",
    "zero_fiiled = tFT(usksp,sensmaps)\n",
    "undersample_kspace = usksp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoiser(scorenet, sigma, x, step_lr=0.9, c=4):\n",
    "    sigma = torch.tensor(sigma).to(x.device)\n",
    "    sigma = sigma.unsqueeze(-1).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
    "    v_var = x.repeat(1,3,1,1)\n",
    "    noise = torch.randn_like(v_var).clip(-1,1) * sigma * np.sqrt(2)\n",
    "    \n",
    "    inputs = v_var + noise\n",
    "    logp = scorenet(inputs, sigma)\n",
    "    clip_c = c*sigma.squeeze().item()\n",
    "    residual = step_lr*torch.clamp(logp*sigma**2,-clip_c,clip_c)\n",
    "    v = x + tensor_split(residual)\n",
    "    return v\n",
    "\n",
    "gamma=1.15\n",
    "lam=1e-4\n",
    "rho=0.003\n",
    "max_iter = 300\n",
    "eps=1e-9\n",
    "step_lr=0.5\n",
    "c=3\n",
    "verbose=True\n",
    "\n",
    "ori_complex = orim\n",
    "ori_complex = ori_complex/np.max(np.abs(ori_complex))\n",
    "image_initial = numpy2tensor(zero_fiiled).permute(2,0,1).unsqueeze(0).cuda()\n",
    "image_target = numpy2tensor(ori_complex).permute(2,0,1).unsqueeze(0).cuda()\n",
    "v = image_initial\n",
    "x = v.clone()\n",
    "u = torch.zeros_like(v)\n",
    "\n",
    "psnrs = []\n",
    "rho_k = rho\n",
    "time1 = time.time()\n",
    "for idx in range(max_iter):\n",
    "    x_old = x.clone()\n",
    "    v_old = v.clone()\n",
    "    u_old = u.clone()\n",
    "    #-----------------------------------------------\n",
    "    # denoising step\n",
    "    #-----------------------------------------------\n",
    "    sigma = math.sqrt(lam/rho_k)\n",
    "    with torch.no_grad():\n",
    "        v = denoiser(scorenet, sigma, x + u, step_lr=0.9, c=4)\n",
    "\n",
    "    #-----------------------------------------------\n",
    "    # projection step\n",
    "    #-----------------------------------------------\n",
    "    v_sub_u = tensor_split(v - u)\n",
    "    \n",
    "    v_sub_u = tensor2complex(v_sub_u)[0]\n",
    "    \n",
    "    iterkspace = FT(v_sub_u,sensmaps)\n",
    "    iterkspace = (undersample_kspace + (1e-4*rho)*iterkspace)/(mask[:,:,np.newaxis] + 1e-4*rho)#*(1-mask)[:,:,np.newaxis]\n",
    "    x = tFT(iterkspace,sensmaps)\n",
    "    #-----------------------------------------------\n",
    "    # multiplier update step\n",
    "    #-----------------------------------------------\n",
    "    u = x - v_sub_u\n",
    "    \n",
    "    u = numpy2tensor(u).permute(2,0,1).unsqueeze(0).to(v.device)\n",
    "    x = numpy2tensor(x).permute(2,0,1).unsqueeze(0).to(v.device)\n",
    "    \n",
    "\n",
    "    if image_target is not None:\n",
    "        PSNR = batch_PSNR(image_target, tensor_split(x))\n",
    "        psnrs.append(PSNR)\n",
    "\n",
    "    rho_k = gamma*rho_k\n",
    "\n",
    "    if verbose and (idx%10 == 0):\n",
    "        print(f'iter: {idx}, rho: {rho_k}, sigma: {int(sigma*255)}, PSNR: {PSNR}, TIME: {time.time()-time1}')\n",
    "\n",
    "    delta = (v_old-v).pow(2).mean() + (u_old-u).pow(2).mean() + (x_old-x).pow(2).mean()\n",
    "    if delta < eps:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.abs(rec_multicoil_ddp[...,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the result of ddp\n",
    "import pickle\n",
    "rec_multicoil_ddp = pickle.load(open('./data/ddp/rec_ddp_espirit_normed', 'rb'))\n",
    "rec_im_ddp = np.abs(rec_multicoil_ddp[1:,:,-1])\n",
    "psnr(rec_im_ddp, np.abs(orim)/np.max(np.abs(orim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the result of TRPA\n",
    "psnr(tensor2image(x)[0], np.abs(orim)/np.max(np.abs(orim)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
